
\subsection{Factorize kernel codes with templates}

During the refactoring of the library code, we had to factorize the code from very close kernels. It would not have been maintainable to keep multiple kernels extremely similar. However, it is not viable to directly make a generic kernel with \verb|if - then - else| conditions inside, since it would create a major slowdown. This is because GPU execution runs the same instructions for all threads in an ensemble of threads called warp. For most NVIDIA GPUs, warps are made of 32 threads. Introducing conditions would make a divergence between the threads in the warp, creating different contexts and not running threads concurrently.

The solution we adopted consists in using C++ templates to generate multiple specialized version of a kernel at compilation time. We can then write branches in a clean fashion that would be resolved by the compiler. However, we cannot make any conditions on integer values from the get-go: since templates are resolved at compilation, the compiler can only resolve symbols on classes and types, and not values. 

We then use a small template as shown on listing~\ref{lst:tmp} to derive our own types from integer values. We first define a template structure \verb|Int2Type| with inside an enumeration with a single value, equal to the one given for its template instantiation. The goal is to instantiate empty structures which are seen distinctly by the compiler. Hence, at compilation time, \verb|Int2Type<0>| is a structure name, \verb|Int2Type<1>| is another structure, and so on.

We then create a template structure \verb|SameType| that can be instantiated in two ways: if two objects of different types are passed (line 5), it bears an enumeration with value 0, and if types are the same (line 9), it bears value 1. Writing \verb|if| blocks using the \verb|SAMETYPE(a, b)| macro will expand it into 0 or 1, allowing the compiler to prune the unused branch automatically.

\begin{listing}[h!]
	\begin{minted}[
	frame=lines,
	framesep=2mm,
	baselinestretch=1.2,
	fontsize=\footnotesize,
	linenos,
	breaklines,
	frame=single]{C++}
template <int Val>
struct Int2Type{
	enum {val_ = Val} dummy;
};
template<typename X, typename Y>
struct SameType {
	enum { result = 0 };
};
template<typename T>
struct SameType<T, T> {
	enum { result = 1 };
};
#define SAMETYPE(a, b) (SameType<a,b>::result)
	\end{minted}

	
	\caption{Meta-programming template to derivate types from integer values}
	\label{lst:tmp}
\end{listing}
	
Finally, for all the kernels to be generated, explicit calls must be written in the source code. We decided to group all the kernels in three major kernel templates. Each of them can specialize to various extent:

\begin{itemize}
	\item global, that does not have any specialisation,
	\item local, on which we can select among 4 combinations:
	\begin{itemize}
		\item start position calculation (on / off),
		\item second-best score calculation (on / off);
	\end{itemize}
	\item semi-global, on which we can select among 64 combinations:
	\begin{itemize}
		\item if we allow to skip the beginning, the end, both ends or none of the ends of either query or target (making it 16 different cases),
		\item start position calculation (on / off),
		\item second-best score calculation (on / off).
	\end{itemize}
\end{itemize}

It would be highly unpractical to list all these variations, but we had to have them written before the compilation phase, where the templates are resolved. Subsequently, we rely on the C++ preprocessor and used a series of macro expansion to develop a \verb|switch - case| including all variations. This allows to write each kernel call exactly once, and condense all calls in a clean way.

\subsection{Porting newer version of GASAL2 in GASE-GASAL2}

Several modifications to BWA were done to integrate GASAL2 for its extension step. While some of them were already done when starting this thesis, there was an important amount of changes to successfully integrate it. In particular, the system to process sequences in pack was already implemented in a custom version of BWA for measurements called GASE-GASAL2~\cite{Ahmed:gase-gasal2}. For the recall, GASAL2 works with batches of sequences to align, and with a given batch of $k$ alignments, it instantiates $k$ threads that run the alignment kernel on the GPU. This behaviour is intrinsic to how GPU computing works: in fact, we need to run a given kernel, hence complete a given task, on all the parts of a large data set, so we need to provide a batch of data to process in parallel.

This piece of software called GAS-GASAL2 only uses GASAL2 as local aligner and does not provide accurate scores that can be compared with BWA. It has only been developed as a demonstrator of how alignment could be accelerated. It used an old version of GASAL2 which became incompatible with the changes we made previously.

The first task has been to update GASE-GASAL2 to compile it with the newer version of GASAL2. In particular, the source code had to be ported to C++. Several wrong writing practices had to be fixed, including naming variables "or" (which is a keyword in C++), and defining clear context for function prototypes in the header files. In fact, C++ features name mangling for functions, which adds context information at compilation to establish contexts where function names are declared valid. This feature is implemented among others for function overloading. Unless plain C functions are placed in \verb|extern 'C' { ... }| blocks, they cannot be resolved at compilation, inducing a linking error, so some code clean-up had to be done on this side.